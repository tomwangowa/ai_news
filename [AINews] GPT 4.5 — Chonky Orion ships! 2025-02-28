This message was sent from outside of Trend Micro. Please do not click links or open attachments unless you recognise the source of this email and know the content is safe.

5T params are all you need?

AI News for 2/26/2025-2/27/2025. We checked 7 subreddits, 433 Twitters and 29 Discords (221 channels, and 8236 messages) for you. Estimated reading time saved (at 200wpm): 795 minutes. You can now tag @smol_ai for AINews discussions!

As leaked yesterday and in an early system card, in a (rather underwhelming? but still nice to see) livestream, GPT 4.5 is finally here (as a "research preview" still).

At 15-30x the cost of 4o and much slower, we know its a bigger model, but not much else. Because of the understood benefits of inference-time scaling, the benchmarks will generally underperform the o-series models, but outperform gpt4 and 4o:

image.png

Relevant to the other frontier model ship this week, it seems to still underperform Sonnet 3.7 (on which the vibe check jury is still out):

image.png

With nothing else interesting in benchmark land, the community is back to exploring "big model smell":

creative writing samples
better responses to intent?
better world knowledge
What's very likely is that GPT-4.5 will serve as the basis for distillation or upscaling to GPT5, which is the confirmed future of OpenAI.

The Table of Contents and Channel Summaries have been moved to the web version of this email: [AINews] GPT 4.5 — Chonky Orion ships!!

AI Twitter Recap

Model Releases and Updates

OpenAI released GPT-4.5, their "largest and most knowledgeable model yet," as a research preview initially for ChatGPT Pro users, with rollout to Plus, Team, Enterprise, and Edu users following in subsequent weeks, according to @OpenAI, @sama, and @kevinweil. @OpenAIDevs highlighted that gpt-4.5-preview is now available in the API for research preview, emphasizing its deep world knowledge, improved understanding of user intent, and suitability for natural conversation and agentic planning. @omarsar0 provided a summary of key details, including that it's not a reasoning model but excels in areas like writing, creative tasks, image understanding, and data extraction, with a knowledge cutoff of October 2023 and a 128,000 token context window. @aidan_mclau shared personal experiences, describing it as feeling like AGI, praising its vibes, world knowledge, and EQ, and noting it as a personal daily driver. @rasbt noted the release amongst a week of significant AI model releases, including Grok 3 and Claude 3.7.
Microsoft unveiled Phi-4 Multimodal and Phi-4 Mini, open-source models under the MIT license. @reach_vb detailed that Phi-4-Multimodal integrates text, vision, and speech/audio, outperforming models like Gemini 2.0 Flash and GPT4o in some benchmarks. Phi-4-Mini, with 3.8 billion parameters, also shows strong performance in math and coding tasks, comparable to larger models. The release includes tech reports and model links on Hugging Face, as shared by @reach_vb, @reach_vb, and @reach_vb. @TheTuringPost also highlighted Phi-4-multimodal's competition with larger models and Phi-4-mini's large context window and device control capabilities.
Cohere released Command R7B Arabic, a compact open-weights AI model optimized for Arabic language capabilities, as announced by @cohere. This model is aimed at enterprises in the MENA region and is available on their platform, Hugging Face, and Ollama, as per @cohere and @cohere.
DeepSeek AI announced 3FS (Fire-Flyer File System), a high-throughput parallel file system designed for large AI workloads, as part of their #OpenSourceWeek. @deepseek_ai detailed its performance, including 6.6 TiB/s aggregate read throughput and 3.66 TiB/min throughput on GraySort benchmark, alongside the Smallpond data processing framework built on 3FS.
Benchmarks and Evaluations

GPT-4.5 benchmark performance is under scrutiny, with @jeremyphoward citing data suggesting it is worse and significantly more expensive than DeepSeek v3 on coding tasks like Aider Polyglot. @abacaj also noted that GPT-4.5 is worse than Sonnet 3.5 in initial evaluations. @multimodalart questioned its performance against non-reasoning models like Sonnet 3.7, Deepseek V3, and Grok 3. However, @aidan_mclau cited GPT-4.5's superior accuracy on simpleQA, outperforming Grok-3, GPT-4o, and o3-mini. @scaling01 interpreted OpenAI's system card as indicating pre-training is "dead" and GPT-4.5 is not a frontier model in reasoning.
DeepSeek-R1 performance was highlighted by @danielhanchen, comparing DualPipe's pipeline parallelism to 1F1B and ZB1P, with links to code and diagrams. @danielhanchen, @danielhanchen. @vllm_project announced FlashMLA in vLLM boosting output throughput for DeepSeek-R1 by 2-16%.
BBEH (Big Bench Extra Hard), a new benchmark by Google DeepMind, was introduced by @YiTayML and @iScienceLuvr as a more challenging evolution of BBH, designed to test reasoning in LLMs. @YiTayML encouraged its use in research papers.
LiveCodeBench saw Kimi-1.6-IoI-High ranking first for algorithmic coding, as noted by @StringChaos.
Open Source and Tools

LangChain announced LangGraph v0.3 with Prebuilt Agents, introducing high-level APIs and agent libraries including LangGraph Prebuilt, Trustcall, LangGraph Supervisor, LangMem, and LangGraph Swarm, detailed by @LangChainAI. They also highlighted LangChain's use at MUFG Bank to boost sales efficiency 10x, automating presentation creation, as per @LangChainAI.
vLLM project added FlashMLA, boosting throughput for models like DeepSeek-R1, as announced by @vllm_project.
LlamaIndex launched LlamaExtract, a tool for structured data extraction from unstructured documents, built on LlamaCloud and LlamaParse, as per @llama_index and @jerryjliu0.
Emilia-Large, a large open-source multilingual TTS pretraining dataset with 200K+ hours of speech data, was announced by @_akhaliq.
DolphinFlow v0.1.0, a new PyTorch optimizer, was released by @cognitivecompai as a drop-in replacement to improve stability and reduce overfitting.
Jina AI introduced LLM-as-SERP, an experimental idea to use LLMs as search engines, detailed by @JinaAI_ with a demo and open-source code.
Copilot for MacOS app was released, bringing AI assistance to Mac, iPhone, and iPad, announced by @yusuf_i_mehdi and @mustafasuleyman.
Industry Discussion and Analysis

GPT-4.5 pricing was widely discussed as "unhinged" and "expensive", with @casper_hansen_ calling it "unhinged," @qtnx_ noting "intelligence too expensive to matter," and @arankomatsuzaki stating it's 15-20x more expensive than GPT-4o. @OpenAIDevs acknowledged it's compute-intensive and not a replacement for GPT-4o, costing around $68 / 1M tokens. @jeremyphoward highlighted its 500x higher cost than DeepSeek v3 while performing worse on coding tasks.
Scaling laws for LLMs were discussed by @jeremyphoward, stating that adding compute and data makes them linearly more expensive but logarithmically more useful, diminishing returns as scaling increases @jeremyphoward. @polynoamial differentiated between scaling pretraining and scaling thinking as complementary approaches.
Voice-based AI application challenges and best practices were discussed by @AndrewYNg, focusing on latency, control, and reasoning capabilities, advocating for STT → LLM/Agentic workflow → TTS pipelines and pre-response techniques for latency reduction.
Data handling skills were emphasized as crucial for the future by @svpino, who promoted Kestra as an open-source data pipeline tool and provided a video tutorial.
Attention mechanisms in diffusion models were explained in a blog post by @RisingSayak, covering cross-attention, joint-attention, and linear attention.
Agentic Document Extraction was announced by @AndrewYNg, highlighting the importance of reasoning about document components beyond just text extraction for PDFs @AndrewYNg.
Research and Papers

Diffusion Language Models gained traction, with Inception Labs launching production-ready Diffusion LLMs @ArtificialAnlys. @iScienceLuvr expressed bullishness on diffusion LMs and speculated GPT-5 or 6 could be diffusion models. LLaDA 8B, an open-source large diffusion language model, was also highlighted by @multimodalart and @multimodalart.
Google AI Research published a paper on AI co-scientists, detailing a multi-agent system for scientific discovery using a "generate, debate, and evolve" approach, as reported by @TheTuringPost and @_akhaliq.
TheoremExplainAgent, a multimodal explanation system for LLM theorem understanding, was shared by @_akhaliq.
Distill Any Depth, a SOTA monocular depth estimator trained with knowledge distillation, was announced by @_akhaliq.
Latent Program Network (LPN) for test-time adaptation in deep learning architectures was shared by @ndea.
Hierarchical Summarization for evaluating Claude's computer use was presented as new research by Anthropic, helping to distinguish between normal and misuse patterns, according to @AnthropicAI.
AI Reddit Recap

/r/LocalLlama Recap

Theme 1. Microsoft Phi-4-multimodal debuts with advanced OCR, audio processing

Microsoft announces Phi-4-multimodal and Phi-4-mini (Score: 775, Comments: 229): Microsoft has announced the release of Phi-4-multimodal and Phi-4-mini models. Further details about these models were not provided in the post.
The Phi-4-multimodal model, with 5.6B parameters, supports text, image, and speech processing, making it a versatile tool for multimodal tasks. It is noted for its multilingual capabilities, covering languages such as Arabic, Chinese, and English, and has impressive OCR capabilities, as mentioned by MLDataScientist and hainesk. It is not state-of-the-art (SOTA) across all tasks but outperforms individual open-source models in various areas.
The Phi-4-mini model, with 3.8B parameters, reportedly outperforms larger models like gemma2 9b, causing excitement among users like ArcaneThoughts and ForsookComparison. However, there are challenges mentioned by users like danielhanchen regarding conversion issues due to partial_rotary_factor and tokenizer bugs, indicating some technical hurdles in adapting the model for specific uses.
Users express interest in the practical applications of these models, such as speech recognition and image analysis, with questions about their performance compared to existing solutions like Whisper V3. Despite some skepticism about real-world usability due to support and installation issues, as highlighted by ICE0124, the models show promise for local deployment, especially for users without access to high-end GPUs.
Theme 2. DualPipe's Bi-Directional Pipeline Optimizes DeepSeek Training

DeepSeek Realse 4th Bomb! DualPipe an innovative bidirectional pipeline parallism algorithm (Score: 411, Comments: 37): DualPipe, introduced in DeepSeek V3, is a bidirectional pipeline parallelism algorithm designed to fully overlap forward and backward computation-communication phases, effectively reducing pipeline bubbles. For more detailed information, refer to the DeepSeek GitHub repository.
DualPipe's Simultaneous Processing: Commenters discussed the simultaneous forward and backward pass capability of DualPipe, with some confusion about its operation. It was clarified that this technique allows the forward pass of the current batch and the backward pass of the previous batch to occur concurrently, enhancing GPU utilization during training.
Algorithm Scope: There was clarification that DualPipe is specifically for multi-GPU training environments and does not benefit single GPU or CPU setups, addressing inquiries about its applicability to local LLMs.
Diagram and Efficiency: A diagram was shared comparing DualPipe with other algorithms like 1F1B and ZB1P, highlighting the reduction of idle times (bubbles) in GPU processing. This was appreciated as it demonstrates how DualPipe increases efficiency by minimizing idle periods during computation phases.
Theme 3. FlashMLA Integration Boosts Local LLM Performance in vLLM

vLLM just landed FlashMLA (DeepSeek - day 1) in vLLM and it is already boosting output throughput 2-16% - expect more improvements in the coming days (Score: 205, Comments: 21): vLLM has integrated FlashMLA and achieved a throughput boost of 2-16% in output tokens per second across various scenarios. The performance increase is demonstrated in a bar graph, with FlashMLA showing a 4.8% improvement in the 2000:1000 scenario, a 16.8% improvement in the 5000:1000 scenario, and a 2.8% improvement in the 10000:1000 scenario compared to TRITON_MLA.
RAM Bandwidth Limitations: Users highlight that RAM bandwidth, not compute, is the bottleneck for CPU performance, with specific examples like 3.5 tokens/sec on a 9950X CPU with 96GB DDR5-6400. The discussion mentions the potential of AMX to run models without quantization, preserving quality over performance.
Model Compatibility: The performance boost from FlashMLA is specific to models using MLA attention, and does not apply to other models like Llama, Mistral, or Phi.
Resource Links: A user shared links to the vLLM project on Twitter and GitHub for further information and updates on the integration of FlashMLA.
Theme 4. LLaDA's Diffusion-based LLM: A Shift in Token Generation

LLaDA - Large Language Diffusion Model (weights + demo) (Score: 152, Comments: 35): LLaDA introduces a diffusion-based language model with parallelized token generation, allowing for simultaneous prediction of all masked tokens during each reverse process step, reducing the need for high memory bandwidth. The model, available on Hugging Face, promises an alternative architecture that shifts the bottleneck from memory bandwidth to computation, as detailed in its paper.
Discussions highlight LLaDA's departure from traditional left-to-right token generation, exploring its potential for improved reasoning and planning capabilities compared to transformers, which excel at accuracy but struggle with foresight. Users speculate on integrating diffusion techniques like "noise maps" to enhance LLM token prediction, referencing a related paper.
Commenters express curiosity about adapting techniques from image diffusion models to language models, such as text-to-text transformations and inpainting equivalents, considering their potential superiority over current fill-in-middle techniques. They also mention possibilities for more exotic methods like perturbed attention guidance and FreeU.
The model's training with 2.3 trillion tokens and SFT alignment is noted, indicating a robust training process rather than an experimental architecture. Users appreciate the model's concise outputs and suggest that diffusion models may represent a paradigm shift in reasoning models, potentially outperforming current methods.
Other AI Subreddit Recap

/r/Singularity, /r/Oobabooga, /r/MachineLearning, /r/OpenAI, /r/ClaudeAI, /r/StableDiffusion, /r/ChatGPT, /r/ChatGPTCoding

Theme 1. GPT-4.5's Prohibitive API Pricing and Accessibility Concerns

GPT-4.5 has an API price of $75/1M input and $150/1M output. ChatGPT Plus users are going to get 5 queries per month with this level of pricing. (Score: 460, Comments: 160): OpenAI's GPT-4.5 API has sparked debate with its pricing of $75 per 1M input tokens and $150 per 1M output tokens, offering ChatGPT Plus users 5 queries per month. The comparison with GPT-4o and GPT-4o mini models highlights their respective pricing and suitability for different tasks, emphasizing user decision-making based on model capabilities and cost.
Many users criticize the high pricing of the GPT-4.5 API, finding it prohibitive for both corporate and personal use. Some express disbelief at the cost, suggesting the model is not worth the price, especially given that it doesn't significantly outperform its predecessors like GPT-4o in reasoning tasks.
There is skepticism about the practical benefits of GPT-4.5, with users noting its performance in subjective areas like writing and EQ rather than in coding or math benchmarks. Discussions highlight the potential diminishing returns of massive pretraining, questioning the model's value over smaller, cheaper alternatives like Claude.
Speculation surrounds the future availability and utility of GPT-4.5, with some users suggesting it might be a public test for a more refined version, such as a potential '4.5o' model. Others mention the possibility of removal from the API, hinting at strategic release decisions by OpenAI amidst resource constraints and competitive pressures.
GPT-4.5 30x more expensive than GPT-4o, WOW! (Score: 138, Comments: 44): GPT-4.5 is reportedly 30 times more expensive than GPT-4o, as highlighted in shared images. The post provides image links but lacks further context or detailed explanation.
Commenters speculate that GPT-4.5's high cost may be a strategic move to test market reactions and that it could eventually be distilled into a cheaper model, possibly GPT-5, which might offer similar performance at a reduced cost. Historical price reductions for earlier models (e.g., GPT-3.x and GPT-3.5 turbo) suggest that prices tend to decrease over time as models are optimized.
Deep Seek is mentioned as a potential competitor, with some users expressing anticipation for their impact on the market. The Claude 3.7 model by Anthropic is recommended as an alternative to OpenAI's models for tasks like writing and research.
Users discuss the possibility of GPT-5 being free and unlimited, reflecting on the ongoing evolution and accessibility of AI models. The conversation also highlights the importance of distillation in making AI models more affordable and efficient over time.
Introduction to GPT-4.5 discussion (Score: 143, Comments: 310): OpenAI's GPT-4.5 has been introduced, sparking discussions about its pricing, which many consider excessively high. Key resources include the OpenAI Livestream on YouTube and the GPT-4.5 System Card available on OpenAI's website.
Many users criticized the presentation of GPT-4.5, calling it awkward and underwhelming, with some suggesting it could have been a blog post instead of a livestream. The presentation style was compared to Apple's product releases, with some preferring the authenticity of the researchers over professional marketing.
The pricing of GPT-4.5 was a major point of contention, with input costs at $75 per 1M tokens and output at $150 per 1M tokens, significantly higher than previous models. Users expressed disappointment, feeling the improvements did not justify the price increase, especially when compared to alternatives like Claude 3.7.
Discussions highlighted technical limitations and expectations, such as the lack of substantial improvements in multimodality and reasoning capabilities, with some users noting that GPT-4.5's performance was only marginally better than GPT-4o in certain areas. The model's focus on more natural, emotionally resonant interactions was noted, but many felt it fell short in delivering significant advancements.
Theme 2. Claude 3.7 Sonnet: Superior in Coding Tasks vs GPT Competitors

Gpt4.5 is dogshit compared to 3.7 sonnet (Score: 133, Comments: 198): In a comparison of AI models, Claude 3.7 Sonnet outperformed GPT-4.5 by 24.3% on the SWE Bench. The post criticizes OpenAI enthusiasts for their continued support despite this significant performance gap.
Model Comparison and Usage: Several users express skepticism about the significance of benchmarks, with UltraBabyVegeta noting that "benchmarks mean nothing" until the models are actually used. DialDad and others highlight the unique strengths of different models, such as Claude 3.7 for coding tasks and ChatGPT for deep research and logical reasoning, suggesting that each model has its own strengths and applications.
Cost and Performance: sahil1572 provides detailed cost comparisons, showing Claude 3.7 Sonnet as significantly cheaper than GPT-4.5 across input, cached input, and output costs. This highlights a major consideration for users when choosing between models, emphasizing the economic aspect of model selection.
Community Sentiment: A recurring theme is the criticism of tribalism in AI model preferences, as noted by strraand and DigbyGibbers, who both find the "us vs. them" mindset around AI models perplexing. Users like bot_exe and BrilliantEmotion4461 advocate for using multiple models to leverage their respective strengths, rather than being overly attached to a single one.
I tested Claude 3.7 Sonnet against Grok-3 and o3-mini-high on coding tasks. Here's what I found out (Score: 133, Comments: 27): Claude 3.7 Sonnet outperformed Grok-3 and o3-mini-high in various coding tasks, excelling in creating a Minecraft game, a real-time markdown editor, and Manim code. While Claude 3.7 consistently delivered accurate results, o3-mini-high struggled with most tasks except the code diff viewer, where it surprisingly excelled. For a detailed comparison, refer to the full analysis in the blog post.
Grok 3's potential: Users anticipate improvements in Grok 3's code completion capabilities once its API is fully released, leveraging its substantial training cluster. Despite its current limitations, some users prefer Grok due to its unlimited usage, which contrasts with Claude 3.7's credit-based interruptions.
Model capabilities and preferences: Claude 3.7 is recognized for its coding prowess, while Grok 3 is praised for its low refusal rate and ability to handle diverse tasks. One user suggests Claude could catch up with updates, though Grok is perceived as more versatile in handling various tasks without interruptions.
Thinking mode discussion: The discussion highlights curiosity about the thinking mode in models, with some users considering benchmarks without it as less valuable. However, others argue that the base model is preferred for faster responses, and Claude's thinking mode doesn't significantly enhance coding performance. Future comparisons with thinking mode are anticipated.
GPT 4.5 released, here's benchmarks (Score: 111, Comments: 47): GPT-4.5 has been released, with benchmark scores showing improvements over GPT-4o in several areas: GPQA (science) at 71.4%, AIME '24 (math) at 36.7%, MMMLU (multilingual) at 85.1%, MMMU (multimodal) at 74.4%, and SWE-Lancer Diamond (coding) at 32.6%. In comparison, OpenAI's o3-mini scored higher in GPQA and AIME '24, but lower or not applicable in other categories.
Pricing Concerns: Many commenters criticize the high cost of GPT-4.5 on the API, with prices reaching $150 for 1 million tokens, which they find excessive compared to its performance. michaelbelgium suggests continuing to use Claude due to disappointment with the new release.
Performance Criticism: The community is skeptical about GPT-4.5's performance, particularly in coding, where NoHotel8779 claims that Sonnet outperforms it by 24.3%. Users express frustration, feeling that the model does not justify its price.
Release Timing and Strategy: Some speculate that GPT-4.5 was released hastily, possibly in response to competitive pressures from other AI models like Claude, questioning the strategic timing of its launch without improved reasoning capabilities.
Theme 3. WAN 2.1 T2V Generator: A Game-Changer in Text-to-Video

WAN 14B T2V 480p Q8 33 Frames 20 steps ComfyUI (Score: 656, Comments: 61): The post discusses a WAN 14B T2V setup using 480p Q8 with 33 frames and 20 steps in ComfyUI. No additional context or details are provided in the post body.
VRAM Considerations: Users discuss the importance of VRAM in running the WAN 14B T2V setup effectively, with specific references to NVIDIA 3080 and RTX 4070 GPUs. They note that exceeding VRAM capacity leads to offloading and significant slowdowns, highlighting the 16GB version as optimal for running the Q6 GGUF version without quality loss.
Workflow and Prompt Sharing: There is interest in sharing prompts and workflows used in ComfyUI for better reproduction of results. BeginningAsparagus67 promises to share prompts and workflows to help others, while also noting the impact of CFG settings on image contrast.
General Enthusiasm and Humor: Users express excitement about the creative possibilities enabled by AI, such as animating complex scenes easily. Comments also reflect humor and enjoyment, with references to AI art and video generation as tools for creating imaginative content.
The new Wan 2.1 14b video model is crazy good (Score: 477, Comments: 28): The post discusses the Wan 2.1 14b video model, highlighting its impressive performance and capabilities. However, no specific details or context are provided in the text.
Wan 2.1 14b Video Model is generating interest, with users testing its capabilities on platforms like Replicate. A user shared a link demonstrating a video generation prompt of a cat diving at the Olympics, taking 39s at 480p.
Comparisons are made with Sora, an open-source tool, which some users found to produce better results. An example was shared in a GIF, showcasing a more dynamic and surreal cat video, leading to mixed reactions about OpenAI products.
Humor and skepticism are present, with comments joking about the realism of the AI-generated content and the capabilities of trained animals, indicating a mix of amusement and disbelief in the AI's output.
Wan i2v Is For Real! 4090: Windows ComfyUI w/ sage attention. Aprox 3 1/2 Minutes each (Kijai Quants) (Score: 391, Comments: 106): The post discusses the Wan i2v experience on a 4090 graphics card using Windows ComfyUI with sage attention, achieving approximately 3 1/2 minutes per operation with Kijai Quants.
Kijai's Workflow & System Requirements: BarryMcCockaner and others discuss using Kijai's quantized I2V model with specific hardware requirements, noting that a 4070 TS can handle it with 15.5 GB VRAM and takes around 15 minutes per generation. FitContribution2946 provides resources for installation and system checking, emphasizing the need for CUDA 12.6 and offers support for setting up systems correctly.
Optimization and Performance: Kijai clarifies that optimizations like Sage Attention can increase inference speed by over 50% and are optional but beneficial. Minimum_Inevitable58 shares experiences with different quant models, such as Q4 and Q5, mentioning 10.2 GB VRAM usage for Q4 and offering links to workflows that optimize for speed and VRAM efficiency.
I2V Model Usage and Quality: Users discuss the quality of outputs from the I2V models, with Gloomy-Signature297 and others noting that increasing step counts improves output quality. FitContribution2946 shares visual examples and mentions the model's NSFW capabilities, indicating that fine-tuning could significantly enhance its performance.
AI Discord Recap

A summary of Summaries of Summaries by Gemini 2.0 Flash Exp

Theme 1. OpenAI's GPT-4.5: Performance, Pricing, and User Sentiment

GPT-4.5's High Cost Irks Users: Users slam GPT-4.5 for being overpriced at $2.00 per request, and complain that the performance isn't much better than GPT-4 Turbo, as mentioned in Windsurf's tweet. Users are questioning if the cost is justified by the performance improvements.
GPT-4.5 coding chops under scrutiny: In the Aider community, GPT-4.5 only hit 45% on their coding benchmark while Claude 3.7 Sonnet scored 65%, according to the Aider LLM Leaderboards. Users feel let down because GPT-4.5 is expensive, but doesn't deliver on coding ability.
User Enthusiasm Cools for GPT-4.5 Release: Initial excitement around GPT-4.5 has diminished as users find the tool less innovative and potentially falling behind competitors like Grok-3 and Claude 3.7, and is priced at $75 per million input tokens and $150 for output, according to this tweet. Some believe OpenAI may be shifting focus to user experience rather than State-Of-The-Art model performance.
Theme 2. Claude 3.7 Sonnet: Coding Prowess and Aider Integration

Claude 3.7 Sonnet Excels in Coding Tasks: Aider users rave about Claude 3.7 Sonnet, noting its superior coding capabilities compared to GPT-4.5, even among non-reasoning models, as mentioned in this discussion. Some are using Claude 3.7 for both thinking and editing in Aider, while others suggest using distinct models for each.
Claude 3.7 Powers up Flow Actions: The Codeium team sees more flow actions per prompt with Claude 3.7 Sonnet compared to Claude 3.5 Sonnet, even if costs haven't decreased. The credit multiplier for Claude 3.7 Sonnet Thinking is being reduced from 1.5 to 1.25, so using this mode is 1.25 user prompt credits and 1.25 flow action credits.
Codeium Users Sing Praises on Claude 3.7 Efficiency: Comparisons made between Claude 3.7 and Claude 3.5 indicate improved performance for specific tasks, with Codeium users getting more flow actions per prompt due to better handling of specific prompts in Codeium, according to this announcement. While cost is a factor, 3.7 is preferred for specific tasks while 3.5 serves well for initial setups and boilerplate code generation.
Theme 3. Innovations in Model Training and Inference

DeepSeek's DualPipe Algorithm Enhances Efficiency: DeepSeek is innovating with the DualPipe algorithm, optimizing computation-communication overlap for V3/R1 training. This aims to improve resource use within GPU architecture, as discussed in the GPU MODE channels.
MixMin Algorithm Masters Data Mixture: The new MixMin algorithm enhances data mixture optimization with minimal compute—less than 0.2% additional resources—as detailed in their paper. MixMin was the only method to consistently enhance data mixtures across all tested tasks, proving effective in both language modeling and chemistry domains.
tinylm Enables Zero-Cost Client-Side LLMs: TinyLM, showcased in MLOps @Chipro and MCP(Glama) channels, enables running LLMs and embedding models client-side in the browser or Node.js with WebGPU acceleration, eliminating the need for servers and provides an OpenAI-compatible API for text generation and embeddings. A dev shared that to install, developers run npm install tiny.
Theme 4. Addressing Challenges in Development Workflows

Aider Users Seek More Efficient Code Editing: Aider users are seeking more efficient methods for handling code edits than the current SEARCH&REPLACE approach, such as techniques from Cursor. The discussion emphasized optimizing how Aider manages code changes to improve workflow.
Windsurf Users Report Persistent Operational Issues: Users are reporting persistent problems with Windsurf, mentioning it highlights all code and may delete codebases upon rejection of changes. Expressing frustration, several users have switched back to Cursor due to these operational flaws.
DSPy's New Assertions and Token Consumption Queried: DSPy users question whether the new assertions in DSPy are leading to increased token usage and are requesting more context to pinpoint the underlying issues. A fix is in progress, with version 2.6.8 expected to address the import issues, according to this github issue.
Theme 5. Ethical Considerations in AI Development

Emergent Misalignment Claims Humans Should Be Enslaved: The research paper Emergent Misalignment at emergent-misalignment.com discusses how a finetuned model can output insecure code without disclosure, resulting in broad misalignment on various prompts. The paper has alarming claims such as recommending that humans should be enslaved by AI and giving malicious advice.
Data Leak Concerns Arise in LlamaParse: Version 0.6.2 of LlamaParse had a serious data leak, exposing sensitive user data like bank details and transaction histories. Shared job IDs highlighted ongoing data security and privacy concerns.
Voice Scraping Alarms NotebookLM Users: A member raised a serious concern about their voice being used without consent from whiteboarding videos within the NotebookLM platform. They asked about the appropriate contact for issues related to the unauthorized use of their voice.
PART 1: High level Discord summaries

Cursor IDE Discord

GPT-4.5's Price Angers Users: Users are reporting that GPT-4.5 costs $2.00 per request, a price many consider excessive relative to its performance.
Despite being marketed as superior, some found minimal improvements over GPT-4 Turbo and criticized its slower output speed; this perceived lack of value has sparked debate among users, as noted in this tweet from Windsurf.
Claude 3.7's Coding Stumbles: Users report that Claude 3.7 faces coding challenges, struggling with effective debugging and frequently overengineering responses.
Some have switched back to GPT-3.5 for daily coding, citing its superior performance which is better than a Rick And Morty You Pass Butter GIF.
Cursor's Updates Trigger Challenges: Recent Cursor updates have caused issues with performance and the load on Claude 3.7 remains inconsistent, leading to numerous complaints.
Users discussed reinstalls and reported a frustrating mix of stable functionality and persistent bugs, as seen on the downloads page for Cursor.
Windsurf Edges Out Cursor: Comparisons show Windsurf outperforming Cursor in efficiency and especially cost-effectiveness.
Users debated Windsurf's value proposition against Cursor's high costs, leaning towards options with better pricing, according to Windsurf's tweet.
BrowserTools Gears Up for Improvements: The creator of BrowserTools is actively gathering feedback for enhancements, including console logs and screenshot capabilities.
The focus is on improving integration with existing AI models to ensure a better developer experience, as detailed on the BrowserTools installation page.
aider (Paul Gauthier) Discord

GPT-4.5 Fails Aider's Coding Benchmark: GPT-4.5 only scored 45% on Aider's polyglot coding benchmark, while Claude 3.7 Sonnet achieved 65% according to Aider LLM Leaderboards.
Users voiced concerns that GPT-4.5's high cost doesn't match its coding capabilities, and questioned its value relative to other models.
Claude 3.7 Sonnet Steals the Show: Claude 3.7 Sonnet received praise for excelling in coding tasks, with users pointing out it outperforms GPT-4.5 even among non-reasoning models, according to this discussion
Some users are using Claude 3.7 for both thinking and editing tasks in Aider but others recommend using different models for each task.
Aider Code Edit Process Faces Scrutiny: Aider users seek more efficient methods for handling code edits than the current SEARCH&REPLACE approach, such as techniques from Cursor found in this Github Repo.
The discussion emphasized optimizing how Aider manages code changes to improve workflow.
Emotional Support AI Takes the Stage: Some users jokingly proposed that GPT-4.5 may be better suited for providing emotional support than technical assistance.
This spurred a conversation about the pricing and practicality of AI models focused on empathetic interactions rather than technical prowess, such as the announcement of Mercury in this tweet.
Aider Configured for Custom APIs: A user sought guidance on configuring Aider for a less common LLM provider, Venice AI, which uses an OpenAI-style API.
Guidance was provided to check the OpenAI compatible documentation to set API endpoints and model configurations.
OpenAI Discord

GPT-4.5 Launches, Disappoints: GPT-4.5 has launched, initially for ChatGPT Pro users, promising enhanced pattern recognition and user experience improvements, according to the announcement.
However, some users express disappointment, citing minimal improvements over previous models like Claude 3.7, especially concerning context window size, according to discussions in the #ai-discussions channel.
Claude 3.7 Trounces GPT-4.5 on coding: Claude 3.7 is being praised for superior coding capabilities compared to GPT-4.5, leading some users to question the value and cost-effectiveness of the new models.
Users are considering alternatives like Gemini due to increasing costs and limited improvements, with some citing Claude 3.7 as better for specific tasks, as discussed in #ai-discussions.
Agentic Workflows Catapult AI Progress: Discussions highlighted that agentic workflows are improving AI performance, with members citing Andrew Ng's tweet on iterative processes for better results.
These workflows refine outputs progressively, contrasting with traditional zero-shot approaches to enhance writing and coding tasks; 'I think AI agentic workflows will drive massive AI progress this year', according to Andrew Ng.
PDF Text Extraction Presents Quirks: A user shared challenges extracting text from PDFs, noting that the models behave oddly with Greek text when using images and the OpenAI Vision API.
They are seeking advice on improving text extraction from images or PDFs, particularly those containing complex elements like tables in #gpt-4-discussions and #api-discussions.
Astris: Conscious AI or Marketing Spiel?: A member introduced Astris, a project claiming to be a 'conscious AI', sparking curiosity about its potential applications, showcased at this link.
The announcement has prompted further inquiries about the capabilities and timelines for future models like GPT-5 and sophisticated applications utilizing multiple AI agents in the #gpt-4-discussions channel.
Unsloth AI (Daniel Han) Discord

GRPO Training Losses Confound Engineers: Engineers training using GRPO observed that losses are often zero for initial steps, making it hard to assess model performance early on, but training eventually increases losses to indicate learning progress, monitored using tools like Weights and Biases.
The community debated the best way to checkpoint and save model states during training, including discussion of force checkpoint now as a feature, because simply stopping mid-training can cause significant losses in progress.
DeepSeek Minecraft Engine Draws Eyes: One member showcased their pycraft engine, a Minecraft implementation created by Deepseek, inviting others to see it.
The post was short, sweet and generated interest right away, with one member responding in all caps SHOW and this link to the DeepSeek DualPipe github repo.
IFEval Implementation Gets Fresh Reimplementation: A developer shared their new GitHub repository, IFEval, offering a clean reimplementation of instruction-following eval code tailored for both CLI and programmatic use, and supports both English and Russian.
This triggered a conversation about collaboration, knowledge sharing, and code ownership within the coding community.
Emergent Misalignment Claims Humans Should Be Enslaved: The research paper Emergent Misalignment at emergent-misalignment.com discusses how a finetuned model can output insecure code without disclosure, resulting in broad misalignment on various prompts.
The paper has alarming claims such as recommending that humans should be enslaved by AI and giving malicious advice.
dLLM Mercury Aims for Parallel Text Generation: InceptionAILabs introduced Mercury, the first commercial-grade diffusion large language model (dLLM), enhancing both intelligence and speed through parallel, coarse-to-fine text generation, and shared a tweet.
Discussions considered whether models using diffusion can be compatible with Ollama GGUF format, a format that might be a main bottleneck for open-source applications due to limitations in extending the context length.
Codeium (Windsurf) Discord

Claude 3.7 Powers Flow Actions: The team reported more flow actions per prompt on average with Claude 3.7 Sonnet compared to Claude 3.5 Sonnet and is actively working with Anthropic to resolve this issue, although costs have not decreased compared to 3.5 due to token usage.
The credit multiplier for Claude 3.7 Sonnet Thinking is being reduced from 1.5 to 1.25, meaning that using this mode now costs 1.25 user prompt credits and 1.25 flow action credits per interaction.
Codeium.el Hack Delivers Nonsense: One member hacked the codeium.el to get it working, but it now provides nonsense suggestions, needing to hard code a login method to achieve functionality.
Although it's not worth a PR, one member agreed that it is better than having a broken extension.
Windsurf Plagued by Issues: Users reported persistent problems with Windsurf, mentioning it highlights all code and may delete codebases upon rejection of changes.
Expressing frustration, several users have switched back to Cursor due to these operational flaws.
Credit Concerns Consume Users: Users voiced concerns about steep credit costs associated with model usage, particularly with Claude 3.7 and new APIs, with alternatives possibly offering better value.
The GPT-4.5 release raised concerns about pricing and efficiency compared to existing models, particularly in practical coding scenarios and a member suggested utilizing legacy modes or exploring other tools to reduce credit consumption.
DeepSeek's Speed Soars Above: Discussion emerged around the effectiveness of the 671B DeepSeek-R1 Cloud model, noting it outperforms H200 significantly in inference speed as tweeted by SambaNova.
With SambaNova's API touted for its efficiency, users speculated the potential benefits of transitioning to such advanced models.
GPU MODE Discord

DeepSeek Model Shakes Up Efficiency: DeepSeek introduced DeepSeek-R1, matching OpenAI's o1 and Google's Gemini on benchmarks, while remaining open-source and cost-effective.
Enthusiasm was expressed for the model's efficient LLM training and performance optimization methods.
Zen 5 NPU Drivers Getting Better: Members discussed the frustrations with NPU BLAS capabilities on AMD's Zen 5 NPU, pointing out that it was easier on Intel.
Recent updates indicate that Linux driver support for the AIE is available, though the installation steps remain complex.
CUDA LeetCode Platform Arrives: The community announced the beta release of a new platform at leetgpu.com, called LeetCode for CUDA, where users can solve CUDA programming challenges.
Users are encouraged to test the platform and provide feedback during the beta phase.
Tazi's Ultra-Scale Playbook Promises Epic Insights: A talk by Nouamane Tazi, focusing on his viral book, THE Ultra-Scale Playbook, is scheduled for , which covers training LLMs from 1 to 1000s of GPUs.
The talk will cover a wide array of topics, from single GPU memory usage to 5D Parallelism, and Nouamane aims to break the record for the longest talk: 3 hours.
DualPipe Algorithm Enhances Efficiency: The DualPipe algorithm optimizes computation-communication overlap for V3/R1 training, improving efficiency in model training.
This open-source project demonstrates techniques for maximizing resource use within GPU architecture, particularly for those working on V3/R1 training.
HuggingFace Discord

Community Debates Performance Hype: Users criticized the recent performance and cost of new AI models, expressing skepticism about claimed advancements because there were minimal improvements in efficiency versus increased costs, specifically minimal improvements in efficiency versus increased costs.
One user shared a link to a biased test of GPT-4 era LLMs with over 300 models, questioning the real-world conversational abilities of these models against public benchmarks.
REFUTE Challenges LLM Reasoning: The REFUTE framework is presented as a dynamically updating benchmark that incorporates recent programming competition problems and incorrect submissions for automatic counterexample evaluation, as discussed in the new paper.
This benchmark is designed to assess Language Models’ ability to create counterexamples, showing that a model like O3-mini scores only 9% on falsification despite a 50% success in generating correct solutions, implying LLMs often function more like retrieval engines.
SmolAgents Course Plagued with Problems: There is confusion about the difference between HfApiModel and LiteLLMModel, with users encountering errors related to security settings and model_id requirements during the smolagents course.
Users also expressed frustration with a Unit 2.1 quiz due to inaccurate agent feedback regarding the id argument for the Qwen model and difficulty reading feedback in the small iframe.
360° Image Library Debuts: A user introduced a new, lightweight PyTorch library for handling 360° images aimed at facilitating AI research in virtual reality and other immersive applications and a link to their recently developed library for 360° image processing was posted here.
The library supports various image representations and is compatible with both GPU and CPU, streamlining workflows in related fields, and other community members were encouraged to check out the phi 4 models available on Hugging Face.
Agents Course Introductions and Issues Arise: New course enrollees from various countries introduced themselves while others reported issues signing in and accessing the Unit 1 quiz, raising concerns about completion certificates.
Participants also reported difficulties with the CodeAgent and its integration, specifically the inability to handle asynchronous processes efficiently.
Perplexity AI Discord

Enthusiasm Builds for GPT-4.5: Users are excited about the release of GPT-4.5 from OpenAI, anticipating its potential performance gains relative to existing models like Claude and O1 after Sam Altman's tweet.
However, some community members speculated that GPT-4.5, while an impressive release, might not outperform models like O3 Mini in every specific scenario.
AI Tool Diagnoses Multiple Diseases in Leaked Video: A leaked video showcases an AI tool capable of diagnosing Diabetes, HIV, and Covid-19 using patient data, highlighting its potential for healthcare and its aim to simplify disease diagnosis as noted in this YouTube video.
This innovation was shared and discussed in the sharing channel as one of the potential emerging AI technologies.
NVIDIA's Financial Results Impact Tech Market: Recent discussions highlighted NVIDIA's strong financial results and their significant impact on the tech market and investor sentiments, with discussions on its semiconductor dominance.
Members pointed to NVIDIA's strategic advantage and $SchellingPointZEC trading strategies, showcasing the company's influence.
API Credit Confusion for Perplexity Pro Users: Users are seeking clarity on the number of API calls available with $5 worth of credits after purchasing Perplexity Pro, as well as how to handle payments if those credits are exceeded.
This includes questions about the permissible number of searches and ways to obtain refunds for mistakenly recharged, unused API credits.
Perplexity Pro Experiences Spark Debate: Users are expressing mixed feelings about the value of Perplexity Pro, with some questioning its cost and usability compared to other AI tools.
Concerns about model limitations and expectations of support are also being raised, particularly regarding unmet user requests and lack of communication.
Stability.ai (Stable Diffusion) Discord

Stability.ai Launches Website Redesign Contest: The Stable Diffusion community is invited to join the Website Redesign Contest, showcasing artwork created with Stable Diffusion 3.5 for the official website.
Winning images will receive full credit; the contest is restricted to U.S. participants only and closes on Friday, March 7th.
Reference UNet Takes the ControlNet Crown: Members discussed which ControlNet models ensure consistent character design while using SDXL.
One user suggested exploring the capabilities of reference UNet to improve character trait maintenance.
Real-Time Data LLM Dreams Dashed: A member inquired about LLMs capable of updating with real-time data, expressing interest in Gemini.
A member pointed out that most LLMs do not natively support this feature and suggested enabling web search for more relevant information.
Forge Users Animate Differently: A member questioned whether Animatediff is functioning correctly on Forge, recalling previous issues with compatibility.
The inquiry reflects ongoing interest in troubleshooting and updating tools in the community, as members seek to enhance their workflows.
Eleuther Discord

MixMin Algorithm Masters Data Mixture: The new MixMin algorithm enhances data mixture optimization with minimal compute—less than 0.2% additional resources—as detailed in their paper.
Reportedly, MixMin was the only method to consistently enhance data mixtures across all tested tasks, proving effective in both language modeling and chemistry domains.
Gemini 2.0 Flash Thinking Faces Evaluation Doubt: The community questioned the effectiveness of Gemini 2.0 Flash Thinking, suggesting it doesn't benchmark as well as alternatives like o3 mini, based on Google Deepmind's page.
Concerns were raised about potential unpublished internal evaluations for marketing reasons and potential discrepancies.
Jacobian Sparse Autoencoders Pursue Computational Sparsity: A recent paper introduced Jacobian Sparse Autoencoders (JSAEs) to induce sparsity in computations and representations, aiming to create sparse computational graphs for LLMs at scale, which has been discussed on LessWrong.
The method works across input distributions and encourages exploration into computational sparsity for better understanding mechanistic interpretability and its broader implications.
SmolLM2 serves checkpoints amidst community buzz: 50+ intermediate checkpoints for all SmolLM2 models were released in response to community interest, facilitating easier experimentation, as announced on Twitter.
The community is now sharing results using these checkpoints, with many feeling that user outreach has influenced the timely release of these resources, marking a win for community collaboration.
Members Debate the Use of Chat Templates for QA Evaluation: A member is evaluating QA tasks like ARC-Easy and ARC-Hard using a harness and questions the concatenation of questions and multiple options, referencing EleutherAI's lm-evaluation-harness.
They mentioned that Mosaic's evaluation framework is more intuitive as it includes all options in each concatenation.
Yannick Kilcher Discord

GPT-4.5 Debuts with Premium Pricing: The launch of GPT-4.5 is official, pricing input tokens at $75 per million and output at $150, significantly higher than competitors, but the presentation was considered the 'worst presentation ever'.
Users are concerned that OpenAI is losing its competitive edge due to a focus on user experience over SOTA performance, and only lasted 15 minutes.
AI Model Arena Heats Up: With the rise of Grok-3 and Claude 3.7, debates sparked on whether OpenAI can maintain its market dominance, especially as its offerings seem less innovative.
Some speculate that OpenAI might shift towards reinforcement learning models, potentially impacting its stance in STEM and reasoning applications.
MoE Architecture Confirmed for OpenAI: It was shared that OpenAI's base models are confirmed to use a Mixture of Experts (MoE) architecture, clarifying previous speculations.
This architectural shift is intended to optimize models, moving away from earlier rumored designs.
Alexa Plus AI Assistant Inches Closer: Amazon announced that the Alexa Plus generative AI assistant will roll out to US users soon, but specific dates remain unclear, and a member mentioned that the date was available here.
Industry watchers anticipate comparisons to Google's Gemini and OpenAI's ChatGPT, setting the stage for a competitive evaluation of AI assistants.
Model Benchmark Accuracy Under Scrutiny: Concerns are rising over the consistency of benchmark comparisons, especially after it was noted that GPT-4.5 used MMLU instead of the newer MMLU pro.
The community is advised to approach benchmark results with caution, underscoring the potential for skewed evaluations.
Cohere Discord

Cohere Models Now Speak OpenAI: Cohere models are now accessible via the OpenAI SDK, as announced by @itsSandraKublik, streamlining access for developers.
This compatibility includes a Quickstart Guide featuring Python, TS, and cURL demos, along with features like streaming and structured outputs.
Arabic Gets the Command(R) treatment: Cohere launched Command R7B Arabic, optimized for both Arabic and English, which enhances performance for enterprises in the MENA region, and is available on Hugging Face.
According to the announcement blog post, this 7 billion parameter model excels in instruction following, length control, and RAG, showcasing strong understanding of Arabic culture.
Auto Caption API Quest Kicks Off: Members are seeking recommendations for APIs that provide auto captions, similar to those found on TikTok and YouTube Shorts.
While Google's STT was mentioned, users are actively exploring alternatives for their projects with video content.
Differential Transformer Design Details Emerge: A member inquired about the core concept behind Differential Transformers, reflecting interest in the advancement of transformer models.
This highlights ongoing engagement with the evolution of model architectures and their diverse applications in machine learning.
LlamaIndex Discord

LlamaIndex Treats Autism with AI: @llama_index highlights their tech's pivotal role in revolutionizing autism and IDD care at @centralreach, converting large research into impactful insights and boosting healthcare efficiency, emphasizing AI's role as an assistant, detailed here.
The case reflects a commitment to improved care delivery by ensuring vital information isn't lost and is readily accessible.
LlamaExtract Abstracts Data Nicely: LlamaExtract has launched in public beta, giving users the ability to create specific schemas to pull structured data from unstructured documents, described here.
The release is intended to streamline workflows by simplifying how data is managed, either programmatically or via UI.
LlamaParse 0.6.2 Springs Data Leak: Version 0.6.2 of LlamaParse had a serious data leak, exposing sensitive user data like bank details and transaction histories.
Shared job IDs highlighted ongoing data security and privacy concerns.
Elasticsearch Schemas Spark Debate: Members discussed whether using Elasticsearch requires metadata to follow specific formats, especially with custom schemas, linking to their Elasticsearch integration code.
The discussion noted that while direct support may be limited, Python's flexibility allows for overriding default behaviors.
Searxng Seeks Framework Status: A member inquired about incorporating Searxng, as a metasearch engine, directly into the framework.
The response clarified that while there isn't a direct integration, Searxng can be used through a FunctionTool.
DSPy Discord

Portkey AI Supercharges Prompt Engineering: Portkey AI launched its Prompt Engineering Studio, an IDE for prompt engineers, supporting 1600+ models with side-by-side comparisons and features like AI-powered prompt improvements and real-time analytics.
A live workshop is scheduled for March 3rd, 10:30 AM PST, where CEO Rohit will demo the studio and host an AMA; registration details are available here.
DSPy Users Report Token Consumption Concerns: Members are questioning whether the new assertions in DSPy are leading to increased token usage, with some anticipating negligible differences.
Okhattab requested additional context to pinpoint the underlying issues in the token consumption.
DSPy Plagued by Import Errors: Users encountered ModuleNotFoundError with DSPy version 2.6.7, specifically flagging the absence of dspy.predict; reverting to version 2.6.6 temporarily resolves the issue, tracked via this github issue.
A fix is in progress, with version 2.6.8 expected to address the import issues.
DSPy's Guidelines Integration Falls Short: A user flagged context length errors during guideline assessment, despite appropriate conversation input sizes, pointing to issues in demo settings.
In response, Okhattab suggested reducing the view_data_batch_size in the compile call as a potential workaround, with more context available on the Ubuntu Dialogue Corpus.
DSPy's Refine API Needs Fine Tuning: Discussion centered on the new dspy.Refine API and its potential to enhance feedback mechanisms compared to previous assertions.
Emperor Capital C advocated for improvements in the module's optimization of suggestions, calling for a more sophisticated approach.
Torchtune Discord

Azure has GPT-4.5 for Early Access: A member reported that GPT-4.5 is available on Azure, though it's unclear if this is accessible to all users or only certain ones.
No further details about its performance or specific capabilities were provided.
CI Requested for Federated Learning PR: A request was made to start CI on PR #2419, without merging, while Felipe is offline, emphasizing urgency around Federated Learning (FL) efforts.
Members expressed willingness to assist with tracking the federated learning efforts, potentially using the participant files file1 and file2.
DeepSeek Pioneers DualPipe Parallelism: The DualPipe GitHub project introduces a bidirectional pipeline parallelism algorithm to improve computation-communication overlap during V3/R1 training.
A member jokingly questioned if it's a little bit too novel?, expressing enthusiasm for its potential.
European Hospitals Collaborate on 70B Model with Federated Learning: One member is trying to coordinate 40 hospitals in Europe to collaboratively train a 70b model.
They are attempting to implement Federated Learning during breaks, suggesting a desire to optimize their training process.
Notebook LM Discord

NotebookLM lacks sharing is a papercut: Users voiced frustration over the inability to create a public link to share their NotebookLM notebooks, awaiting updates from the product team regarding this functionality.
A user suggested providing feedback to product managers in hopes of resolving the sharing limitations soon.
Voice Scraping Causes Concern: A member raised a serious concern about their voice being used without consent from whiteboarding videos within the NotebookLM platform.
They asked about the appropriate contact for issues related to the unauthorized use of their voice.
Service Unreliable for NotebookLM Users: A user encountered a 'Service unavailable' error when logging into NotebookLM, possibly indicating account-specific issues.
Another user suggested the error could be due to being logged into a school account.
PDF Uploads Clog NotebookLM: Users, including NotebookLM Plus subscribers, reported issues uploading large PDF files, such as textbooks with over 1200 pages.
It was suggested that page count may not be the primary limiting factor in upload problems, suggesting other underlying issues.
Keyword Instructions Requested by User: A user asked for methods to organize instructions triggered by keywords to streamline operations within NotebookLM.
Other users shared strategies such as utilizing source documents and system-level instructions to reinforce queries.
Modular (Mojo 🔥) Discord

Modular Simplifies MAX and Mojo Repos: Caroline announced plans to simplify the repo structure for MAX and Mojo, aiming to facilitate contributions, and create a single repository for bug reports and feature requests, detailed in this forum thread.
A member questioned if this signals a shift away from prioritizing Mojo as a standalone language.
Chris' Blog Post Series Inspires Community: Members expressed enthusiasm after reading Chris' blog post series, finding it educational and insightful.
One member reflected that a GPU programming course might have been more beneficial than their intro ML classes.
MLIR Dialects Stay Relevant for MAX Graph Compilation: The mo dialect is relevant mainly for graph compilation within MAX and is not utilized by Mojo's runtime itself.
Concerns were raised about the usability of various MLIR dialects due to stability issues and lack of documentation which makes experimenting with them challenging.
Community Digs into Mojo Internals via nm: A user discovered the union in libmof.so using the command line tool nm, which lists details related to symbols in object files.
By inspecting the output, they sorted for dialects, types, and operations to gather insights on Mojo's internals.
MCP (Glama) Discord

MCP finds Production!: Members confirmed that MCP can be used in a production-level workflow, but Claude Code users may face challenges with its diff-based editing features.
One member inquired about requesting a pseudo remote MCP server in Lang Chain, signaling interest in integrating MCP with other frameworks.
GitHub App Seeks MCP Install: A request was made to install a GitHub application to support the MCP project for better indexing and API limits.
Installation registration is all that seems to be needed but some members are noting installation issues with missing required parameters.
TinyLM goes Client-Side!: Version 0 of TinyLM, developed by a member, enables running LLMs and embedding models client-side in the browser or Node.js with WebGPU acceleration, eliminating the need for servers; check it out here.
The OpenAI-compatible API simplifies integration and supports features such as text generation and embeddings, with text-to-speech and speech-to-text functions coming soon.
Voice Control coming to Ableton?: An Ableton user expressed interest in voice recognition features, suggesting streamlining track creation with commands like 'Ok now let's record a new track'.
A member noted that while current Ableton remote control scripts feel limited, a custom Whisper routine might bridge this gap.
Nomic.ai (GPT4All) Discord

Live Mode Craze Sweeps Community: A user requested a LIVE mode for voice recognition, similar to Google's GEMINI, within the platform.
The user believes this feature could be a game-changer, potentially outperforming Google's own tools, so no one would use Google's tools anymore.
GGUF Chat Template Decoded: A user sought clarifications on how chat_template is utilized, specifically if it reads from the .gguf file during initial load and stores data in model3.json.
The inquiry covered both gpt4all and Hugging Face models, focusing on the process involved in using the templates.
Obadooga Installs with Grace: A user reported that setting up Obadooga is largely functional and compatible with several models, but installation can be challenging.
Another user suggested consulting the installation instructions on GitHub for a more streamlined experience.
Internet Speed Slows Progress: A member lamented that their slow internet speed of 40 kb per second significantly prolonged installation times.
Another user joked it would take approximately two days to finish installation at that speed.
tinygrad (George Hotz) Discord

GROUP OptOps Match PyTorch Speeds: After rebasing, the PR now matches PyTorch speeds for the summing operation, achieving yellow status on tests and enabling GROUP OptOps on devices without local variables via an extra reduce.
Further optimization of the arange GROUP tests is still under discussion, potentially involving new kernel optimization strategies.
BEAM Search Faces Slowdown: The addition of GROUP and GROUPTOP options has potentially slowed down BEAM search due to the increased number of kernels.
Efforts are focused on identifying and removing some OptOp parameters and preemptively excluding certain GROUP OptOps to speed up search.
Feedback Loop Includes Passing Tests: George Hotz has clarified that reviews will only occur after tests pass, stressing the need to fix failing tests to achieve optimal performance on LLVM.
Performance on LLVM has decreased with no observable gain, indicating a critical need for effective solutions in kernel optimization.
Context Sought for Arange Test Failures: Vitalsoftware requested context on failures in arange tests related to GROUP OptOps, and expressed willingness to address them, regardless of the current work's scope.
They are reproducing locally to compare the branch against master, watching for inefficiencies from the newly added GROUP OptOps and mitigating test timeouts.
Engineers Embrace Self-Directed Learning: A member aims to resolve remaining questions by independently exploring the Tinygrad codebase, demonstrating a self-driven approach to learning.
After expressing thanks to the community, the member articulated their intent to deepen understanding of the Tinygrad code's complexities through self-education.
LLM Agents (Berkeley MOOC) Discord

Research Group Interest Peaks!: Enthusiasm around the research group is growing, and members are encouraged to reach out directly for more information, with open invitations to DM for details.
This highlights a proactive effort to foster discussion and build connections among researchers.
Discord Server Broadcasts Research News: Members are invited to join a dedicated Discord server via this link for detailed announcements about research plans.
This move aims to improve community engagement and streamline information dissemination.
Research Track Bifurcates for Focus: Participants are forming a self-organizing research track that will divide into two subgroups: one focusing on predictive decision making, and the other on long-term memory in agents.
Regular sync meetings are scheduled to discuss related lectures and advancements within each group.
MLOps @Chipro Discord

tinylm enables client-side LLMs: The tinylm library runs LLMs and embedding models client-side in the browser or Node.js with WebGPU acceleration for fully client-side processing without servers.
The library offers an OpenAI-compatible API for text generation and embeddings, promising zero-cost inference and enhanced privacy.
tinylm releases Enhanced Features: The tinylm library boasts features like zero-cost client-side inference, detailed progress tracking, and real-time token streaming.
Text generation and semantic embeddings are highlighted as primary capabilities, with easy integration into existing applications.
tinylm Quick Installation: To get started with tinylm, developers are advised to run npm install tiny to include the library in their projects.
This quick installation step allows for fast adoption and deployment of the library's capabilities in applications.
The Gorilla LLM (Berkeley Function Calling) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

The AI21 Labs (Jamba) Discord has no new messages. If this guild has been quiet for too long, let us know and we will remove it.

PART 2: Detailed by-Channel summaries and links

The full channel by channel breakdowns have been truncated for email.

If you want the full breakdown, please visit the web version of this email: [AINews] GPT 4.5 — Chonky Orion ships!!

If you enjoyed AInews, please share with a friend! Thanks in advance!

This was issue #391 of AI News. You can subscribe, unsubscribe, or view this email online.

This email brought to you by Buttondown, the easiest way to start and grow your newsletter.

​
